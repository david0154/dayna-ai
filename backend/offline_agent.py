"""\nDayna AI - Bilingual Offline Agent\nSupports Hindi and English with automatic language detection\n\nAuthor: David (Nexuzy Tech)\nLicense: MIT\n"""\n\nimport asyncio\nimport os\nfrom pathlib import Path\nfrom typing import Optional, Callable, Literal\nfrom llama_cpp import Llama\nfrom faster_whisper import WhisperModel\nimport subprocess\nimport tempfile\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass BilingualOfflineAgent:\n    """\n    Offline AI Agent with bilingual Hindi-English support\n    - LLM: Mistral-7B-Instruct (bilingual capable)\n    - STT: Whisper (multi-language)\n    - TTS: Piper (Hindi + English voices)\n    """\n    \n    def __init__(\n        self,\n        model_path: str = \"backend/models/mistral-7b-instruct-v0.2.Q4_K_M.gguf\",\n        whisper_model: str = \"base\",  # Multilingual Whisper\n        hindi_tts_model: str = \"backend/models/hi_IN-pratham-medium.onnx\",\n        english_tts_model: str = \"backend/models/en_US-lessac-medium.onnx\",\n        on_status: Optional[Callable] = None,\n        default_language: Literal[\"hi\", \"en\", \"auto\"] = \"auto\",\n        n_threads: int = 8,\n        n_gpu_layers: int = 35\n    ):\n        self.on_status = on_status\n        self.default_language = default_language\n        \n        print(\"[DAYNA] [OFFLINE] üöÄ Initializing bilingual offline mode...\")\n        \n        # Initialize LLM\n        if self.on_status:\n            self.on_status(\"Loading Mistral-7B model...\")\n        \n        try:\n            self.llm = Llama(\n                model_path=model_path,\n                n_ctx=4096,  # Context window\n                n_threads=n_threads,\n                n_gpu_layers=n_gpu_layers if self._has_gpu() else 0,\n                verbose=False\n            )\n            print(\"[DAYNA] [OFFLINE] ‚úÖ LLM loaded successfully\")\n        except Exception as e:\n            print(f\"[DAYNA] [ERROR] Failed to load LLM: {e}\")\n            raise\n        \n        # Initialize Whisper (multilingual for Hindi + English)\n        if self.on_status:\n            self.on_status(\"Loading Whisper STT (Hindi + English)...\")\n        \n        try:\n            self.whisper = WhisperModel(\n                whisper_model,\n                device=\"cuda\" if self._has_gpu() else \"cpu\",\n                compute_type=\"float16\" if self._has_gpu() else \"int8\"\n            )\n            print(\"[DAYNA] [OFFLINE] ‚úÖ Whisper STT loaded (multilingual)\")\n        except Exception as e:\n            print(f\"[DAYNA] [ERROR] Failed to load Whisper: {e}\")\n            raise\n        \n        # Store TTS model paths\n        self.hindi_tts_model = hindi_tts_model\n        self.english_tts_model = english_tts_model\n        \n        # Verify Piper installation\n        if self.on_status:\n            self.on_status(\"Checking Piper TTS...\")\n        \n        self._verify_piper()\n        print(\"[DAYNA] [OFFLINE] ‚úÖ Piper TTS ready (Hindi + English)\")\n        \n        # Conversation history\n        self.conversation_history = []\n        \n        print(\"[DAYNA] [OFFLINE] üéâ All systems ready!\")\n        \n    def _has_gpu(self) -> bool:\n        \"\"\"Check if CUDA GPU is available\"\"\"\n        try:\n            import torch\n            has_cuda = torch.cuda.is_available()\n            if has_cuda:\n                print(f\"[DAYNA] [GPU] ‚úÖ CUDA detected: {torch.cuda.get_device_name(0)}\")\n            else:\n                print(\"[DAYNA] [CPU] ‚ÑπÔ∏è  No CUDA GPU found, using CPU\")\n            return has_cuda\n        except ImportError:\n            print(\"[DAYNA] [CPU] ‚ÑπÔ∏è  PyTorch not found, using CPU\")\n            return False\n    \n    def _verify_piper(self):\n        \"\"\"Verify Piper TTS is installed\"\"\"\n        try:\n            result = subprocess.run(\n                [\"piper\", \"--version\"],\n                capture_output=True,\n                text=True,\n                timeout=5\n            )\n            if result.returncode == 0:\n                version = result.stdout.strip()\n                print(f\"[DAYNA] [TTS] Piper version: {version}\")\n            else:\n                raise Exception(\"Piper command failed\")\n        except FileNotFoundError:\n            print(\"[DAYNA] [WARN] ‚ö†Ô∏è  Piper TTS not found in PATH\")\n            print(\"[DAYNA] [WARN] Install with: pip install piper-tts\")\n        except Exception as e:\n            print(f\"[DAYNA] [WARN] Piper check failed: {e}\")\n    \n    def _detect_language(self, text: str) -> str:\n        \"\"\"\n        Detect if text is primarily Hindi or English\n        Returns: 'hi' for Hindi, 'en' for English\n        \"\"\"\n        # Check for Devanagari script (U+0900 to U+097F)\n        devanagari_count = sum(1 for char in text if '\\u0900' <= char <= '\\u097F')\n        total_chars = len([c for c in text if c.isalpha()])\n        \n        if total_chars == 0:\n            return \"en\"\n        \n        # If more than 30% Devanagari characters, classify as Hindi\n        hindi_ratio = devanagari_count / total_chars\n        detected = \"hi\" if hindi_ratio > 0.3 else \"en\"\n        \n        logger.debug(f\"Language detection: {detected} (Devanagari: {hindi_ratio:.1%})\")\n        return detected\n    \n    async def transcribe_audio(\n        self,\n        audio_path: str,\n        language: Optional[str] = None\n    ) -> tuple[str, str]:\n        \"\"\"\n        Transcribe audio file using Whisper\n        Args:\n            audio_path: Path to audio file\n            language: Force language ('hi', 'en') or None for auto-detect\n        Returns:\n            (transcribed_text, detected_language_code)\n        \"\"\"\n        # Auto-detect language if not specified\n        if language is None or language == \"auto\":\n            language = None  # Let Whisper auto-detect\n        \n        segments, info = await asyncio.to_thread(\n            self.whisper.transcribe,\n            audio_path,\n            language=language,\n            beam_size=5\n        )\n        \n        text = \" \".join([segment.text for segment in segments])\n        detected_lang = info.language\n        \n        return text.strip(), detected_lang\n    \n    async def generate_response(\n        self,\n        prompt: str,\n        language: str = \"auto\",\n        max_tokens: int = 512,\n        temperature: float = 0.7\n    ) -> tuple[str, str]:\n        \"\"\"\n        Generate response using local Mistral-7B model\n        Args:\n            prompt: User input text\n            language: Response language ('hi', 'en', 'auto')\n            max_tokens: Maximum response length\n            temperature: Creativity (0.0-1.0)\n        Returns:\n            (response_text, response_language)\n        \"\"\"\n        \n        # Detect language if auto\n        if language == \"auto\":\n            language = self._detect_language(prompt)\n        \n        # Build bilingual system prompt\n        if language == \"hi\":\n            system_prompt = \"\"\"‡§Ü‡§™ Dayna ‡§π‡•à‡§Ç, ‡§è‡§ï Advanced AI Assistant ‡§ú‡•ã users ‡§ï‡•Ä ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® tasks ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à‡§Ç‡•§\n‡§Ü‡§™‡§ï‡§æ ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§§‡•ç‡§µ friendly, helpful ‡§î‡§∞ professional ‡§π‡•à‡•§\n‡§Ü‡§™ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§î‡§∞ ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡§º‡•Ä ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§≠‡§æ‡§∑‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§§ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡§Ç‡•§\n‡§Ü‡§™ CAD design, 3D modeling, smart home control, web browsing ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡§Ç‡•§\nUser ‡§ú‡§ø‡§∏ ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§™‡•Ç‡§õ‡•á, ‡§â‡§∏‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§Ç‡•§\"\"\"\n        else:\n            system_prompt = \"\"\"You are Dayna, an Advanced AI Assistant helping users with various tasks.\nYou have a friendly, helpful, and professional personality.\nYou can communicate in both Hindi and English fluently.\nYou can help with CAD design, 3D modeling, smart home control, and web browsing.\nRespond in the same language as the user.\"\"\"\n        \n        # Format prompt for Mistral-Instruct\n        formatted_prompt = f\"<s>[INST] {system_prompt}\\n\\n{prompt} [/INST]\"\n        \n        # Generate response\n        response = await asyncio.to_thread(\n            self.llm,\n            formatted_prompt,\n            max_tokens=max_tokens,\n            temperature=temperature,\n            top_p=0.95,\n            stop=[\"</s>\", \"[INST]\"],\n            echo=False\n        )\n        \n        generated_text = response['choices'][0]['text'].strip()\n        \n        # Detect response language\n        response_lang = self._detect_language(generated_text)\n        \n        # Update conversation history\n        self.conversation_history.append({\n            \"role\": \"user\",\n            \"content\": prompt,\n            \"language\": language\n        })\n        self.conversation_history.append({\n            \"role\": \"assistant\",\n            \"content\": generated_text,\n            \"language\": response_lang\n        })\n        \n        # Keep only last 10 exchanges (20 messages)\n        if len(self.conversation_history) > 20:\n            self.conversation_history = self.conversation_history[-20:]\n        \n        return generated_text, response_lang\n    \n    async def synthesize_speech(\n        self,\n        text: str,\n        language: str = \"auto\",\n        output_path: Optional[str] = None\n    ) -> bytes:\n        \"\"\"\n        Convert text to speech using Piper TTS\n        Supports both Hindi and English\n        Args:\n            text: Text to synthesize\n            language: 'hi', 'en', or 'auto'\n            output_path: Optional output file path\n        Returns:\n            audio_bytes (WAV format, 22050Hz, 16-bit)\n        \"\"\"\n        # Auto-detect language if needed\n        if language == \"auto\":\n            language = self._detect_language(text)\n        \n        # Select appropriate TTS model\n        if language == \"hi\":\n            model_path = self.hindi_tts_model\n            voice_name = \"Hindi (Pratham)\"\n        else:\n            model_path = self.english_tts_model\n            voice_name = \"English (Lessac)\"\n        \n        print(f\"[DAYNA] [TTS] üó£Ô∏è  Using {voice_name}\")\n        \n        # Create temp output if not specified\n        if output_path is None:\n            temp_file = tempfile.NamedTemporaryFile(\n                suffix=\".wav\",\n                delete=False\n            )\n            output_path = temp_file.name\n            temp_file.close()\n        \n        # Run Piper TTS\n        try:\n            process = await asyncio.create_subprocess_exec(\n                \"piper\",\n                \"--model\", model_path,\n                \"--output_file\", output_path,\n                stdin=asyncio.subprocess.PIPE,\n                stdout=asyncio.subprocess.PIPE,\n                stderr=asyncio.subprocess.PIPE\n            )\n            \n            stdout, stderr = await process.communicate(input=text.encode('utf-8'))\n            \n            if process.returncode != 0:\n                error_msg = stderr.decode('utf-8')\n                raise Exception(f\"Piper TTS failed: {error_msg}\")\n            \n            # Read generated audio\n            with open(output_path, 'rb') as f:\n                audio_bytes = f.read()\n            \n            # Clean up temp file\n            if output_path.startswith(tempfile.gettempdir()):\n                os.unlink(output_path)\n            \n            return audio_bytes\n            \n        except Exception as e:\n            print(f\"[DAYNA] [ERROR] ‚ùå TTS synthesis failed: {e}\")\n            raise\n    \n    async def process_voice_input(\n        self,\n        audio_path: str,\n        force_language: Optional[str] = None\n    ) -> tuple[str, bytes, str]:\n        \"\"\"\n        Complete offline voice processing pipeline:\n        1. Transcribe user speech (auto-detect Hindi/English)\n        2. Generate LLM response in same language\n        3. Synthesize TTS audio in detected language\n        \n        Args:\n            audio_path: Path to input audio file\n            force_language: Force specific language ('hi', 'en') or None\n        \n        Returns:\n            (response_text, audio_bytes, language_used)\n        \"\"\"\n        print(f\"[DAYNA] [VOICE] üé§ Processing voice input: {audio_path}\")\n        \n        # Step 1: Speech to Text\n        user_text, detected_lang = await self.transcribe_audio(\n            audio_path,\n            language=force_language\n        )\n        \n        lang_name = \"Hindi\" if detected_lang == \"hi\" else \"English\"\n        print(f\"[DAYNA] [USER] ({lang_name}): {user_text}\")\n        \n        # Step 2: Generate Response\n        response_text, response_lang = await self.generate_response(\n            user_text,\n            language=detected_lang if force_language is None else force_language\n        )\n        \n        resp_lang_name = \"Hindi\" if response_lang == \"hi\" else \"English\"\n        print(f\"[DAYNA] [RESPONSE] ({resp_lang_name}): {response_text}\")\n        \n        # Step 3: Text to Speech\n        audio_bytes = await self.synthesize_speech(\n            response_text,\n            language=response_lang\n        )\n        \n        print(f\"[DAYNA] [VOICE] ‚úÖ Voice processing complete\")\n        return response_text, audio_bytes, response_lang\n    \n    def reset_conversation(self):\n        \"\"\"Clear conversation history\"\"\"\n        self.conversation_history = []\n        print(\"[DAYNA] [OFFLINE] üóëÔ∏è  Conversation history cleared\")\n    \n    def set_language(self, language: Literal[\"hi\", \"en\", \"auto\"]):\n        \"\"\"Set default language preference\"\"\"\n        self.default_language = language\n        lang_name = {\"hi\": \"Hindi\", \"en\": \"English\", \"auto\": \"Auto-detect\"}[language]\n        print(f\"[DAYNA] [CONFIG] üåê Default language set to: {lang_name}\")\n\n\n# Quick test\nif __name__ == \"__main__\":\n    import sys\n    \n    async def test():\n        print(\"\\n" + \"=\" * 50)\n        print(\"DAYNA AI - Bilingual Offline Agent Test\")\n        print(\"=\" * 50 + \"\\n\")\n        \n        agent = BilingualOfflineAgent()\n        \n        # Test English\n        print(\"\\n--- Testing English ---\")\n        resp_en, lang_en = await agent.generate_response(\"Hello! What is your name?\")\n        print(f\"Response ({lang_en}): {resp_en}\")\n        \n        # Test Hindi\n        print(\"\\n--- Testing Hindi ---\")\n        resp_hi, lang_hi = await agent.generate_response(\"‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?\")\n        print(f\"Response ({lang_hi}): {resp_hi}\")\n        \n    asyncio.run(test())\n